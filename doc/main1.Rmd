---
title: "Main Notebook"
output: html_notebook
---

```{r}
list.of.packages <- c("data.table","FeatureHashing","xgboost","dplyr","Matrix","caret","randomForest","lightgbm","magrittr","data.table")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages))
  {
   install.packages(new.packages)
  }
```


```{r} 
#write library
library(lightgbm)
library(magrittr)
library(data.table)
library(randomForest)
library(dplyr)
```

```{r}
train_num<- fread("C:/Users/vc2434/Desktop/fall2017-project5-proj5-grp3-master/output/train_num.csv") %>% as.data.frame()
test_num<- fread("../output/test_num.csv") %>% as.data.frame()
train_num_runique<- fread("../output/train_num_runique.csv") %>% as.data.frame()
test_num<- fread("../output/test_num_runique.csv") %>% as.data.frame()


test = fread("C:/Users/vc2434/Desktop/fall2017-project5-proj5-grp3-master/data/act_test.csv") %>% as.data.frame()
train = fread("C:/Users/vc2434/Desktop/fall2017-project5-proj5-grp3-master/data/act_train.csv") %>% as.data.frame()
people = fread("C:/Users/vc2434/Desktop/fall2017-project5-proj5-grp3-master/data/people.csv") %>% as.data.frame()

names(people)[2:length(names(people))]=paste0('people_',names(people)[2:length(names(people))])
p_logi <- names(people)[which(sapply(people, is.logical))]
for (col in p_logi) {
  set(people, j = col, value = as.numeric(people[[col]]))
}
people$people_group_1[people$people_group_1 %in% names(which(table(people$people_group_1)==1))]='group unique'


train.unique.char_10=
  select(train,people_id,char_10) %>% group_by(char_10) %>% 
  summarize(n=n_distinct(people_id)) %>% 
  filter(n==1) %>% 
  select(char_10) %>%
  as.matrix() %>% 
  as.vector()
train$char_10[train$char_10 %in% train.unique.char_10]='type unique'

data <- merge(train, people, by = "people_id", all.x = T)
data <- lapply(data,as.factor)
data=data.frame(data)
data$date <- as.numeric(as.POSIXct(data$date))
data$people_date <- as.numeric(as.POSIXct(data$people_date))
data <- data[, !names(data) %in% c("activity_id")]

data$people_char_38 <- as.numeric(data$people_char_38)
data <- data[data$people_group_1!="group 17304",]

databack=data
for (f in colnames(data)){  
  if(length(unique(c(data[[f]])))>50){
    levels <- unique(c(data[[f]]))
    data[[f]] <- as.numeric(factor(data[[f]], levels=levels))
  }
}

levels <- unique(c(data[["people_id"]]))
data[[f]] <- as.numeric(factor(data[["people_id"]], levels=levels))


activity1<- data[data$activity_category=="type 1",]
activity1 <- activity1[, !names(activity1) %in% c("row.names")]
activity1=activity1 %>% mutate_if(is.character, as.factor)

data_without_activity1 <- data[data$activity_category!="type 1",]
data_without_activity1 <- data_without_activity1[, !names(data_without_activity1) %in% c("char_1","char_2","char_3","char_4","char_5","char_6","char_7","char_8","char_9","row.names")]
data_without_activity1=data_without_activity1 %>% mutate_if(is.character, as.factor)


for (f in colnames(data)){
  print(typeof(data[[f]]))
}

```


Part 1: Model Selction ######Need to train the best parameters(plz write thsi process into function)

Model1: SVM

Model2: Logistic Regression

Model3: Random Forest:

```{r}
  
thisdata<-data_without_activity1
sqrt(length(thisdata))

  library(randomForest)  
  trainingIndex=sample(nrow(thisdata), round((nrow(thisdata)*0.40)))
  data.test=thisdata[-trainingIndex,]
  data.train=thisdata[trainingIndex,]
  
  rf.model = randomForest(as.factor(outcome)~., data=thisdata, subset= trainingIndex, mtry =7, importance=TRUE)
  importance(rf.model)  
list(rf.model, data.test,trainingIndex)


  train_num = train_num[, !names(train_num) %in% c("V1")]
  length(train_num)
  fit <- randomForest(as.factor(outcome)~., data= train_num, mtry=8,
                      importance=TRUE, 
                      ntree=25)
  
```


Model4: GBM

Model5: LightGBM:

```{r}
DT2mat <- function(DT, low_mem = FALSE, collect = 0, silent = TRUE) {
  
  # Can't initialize lower
  mat_sub <- matrix(rep(FALSE, nrow(DT) * ncol(DT)), ncol = ncol(DT))
  
  cols <- copy(colnames(DT))
  colnames(mat_sub) <- cols
  
  if (collect == 0) {
    # Don't garbage collect
    
    if (low_mem == TRUE) {
      # delete old
      for (i in cols) {
        mat_sub[, which(cols %in% i)] <- copy(DT[[i]])
        set(DT, j = i, value = NULL)
      }
      
    } else {
      # not low mem
      for (i in cols) {
        mat_sub[, which(cols %in% i)] <- copy(DT[[i]])
      }
      
    }
    
  } else {
    # Do garbage collect
    
    if (silent == FALSE) {
      # not silent
      
      if (low_mem == TRUE) {
        # delete old
        j <- 1
        for (i in cols) {
          j <- j + 1
          mat_sub[, which(cols %in% i)] <- copy(DT[[i]])
          set(DT, j = i, value = NULL)
          if (!(j %% collect)) {gc(verbose = FALSE); cat("\rIteration: ", j, ".", sep = "")}
        }
        
      } else {
        # not low mem
        j <- 0
        for (i in cols) {
          j <- j + 1
          mat_sub[, which(cols %in% i)] <- copy(DT[[i]])
          if (!(j %% collect)) {gc(verbose = FALSE); cat("\rIteration: ", j, ".", sep = "")}
        }
        
      }
      
    } else {
      
      if (low_mem == TRUE) {
        # delete old
        j <- 1
        for (i in cols) {
          j <- j + 1
          mat_sub[, which(cols %in% i)] <- copy(DT[[i]])
          set(DT, j = i, value = NULL)
          if (!(j %% collect)) {gc(verbose = FALSE)}
        }
        
      } else {
        # not fast
        j <- 0
        for (i in cols) {
          j <- j + 1
          mat_sub[, which(cols %in% i)] <- copy(DT[[i]])
          if (!(j %% collect)) {gc(verbose = FALSE)}
        }
        
      }
      
    }
  }
  
  return(mat_sub)
  
}
```

```{r}




#manual treatment:
train_num$people_id <- as.numeric(as.factor(train_num$people_id)) - 1
train_num$activity_id <- as.numeric(as.factor(train_num$activity_id)) - 1
train_num$date <- as.numeric(as.factor(train_num$date)) - 1
train_num$people_date <- as.numeric(as.factor(train_num$people_date)) - 1
train_num = train_num[, !names(train_num) %in% c("V1")]
train_num_data= train_num[, !names(train_num) %in% c("outcome")]

#automated treatment
rules <- lgb.prepare_rules(data = train_agg)
data_train <- bank_rules$data


temp_train <- lgb.Dataset(DT2mat(train_num_data), label=train_num$outcome, free_raw_data = FALSE, colnames = colnames(train_num_data), categorical_feature = c(1, 2, 3, 18))

bst <- lightgbm(data = temp_train,
                num_leaves = 4,
                learning_rate = 1,
                nrounds = 2,
                objective = "binary")

pred <- predict(bst, DT2mat(train_num_data))
err <- mean(as.numeric(pred > 0.5) != train_num$outcome)
print(paste("test-error=", err))


print("Training lightgbm with lgb.Dataset")
dtrain <- lgb.Dataset(data = test_num[, !names(test_num) %in% c("V1", "outcome")],
                      label = test_num$outcome)
bst <- lightgbm(data = dtrain,
                num_leaves = 4,
                learning_rate = 1,
                nrounds = 2,
objective = "binary")

bst <- lightgbm(data = as.matrix(train_num$data),
                label = train$label,
                num_leaves = 4,
                learning_rate = 1,
                nrounds = 2,
objective = "binary")
```

Model6: Xgboost

Model7: Neural Network

Part 2: Feature Selection

1. Feature Importance

2. PCA

3.Bag of words techniques

Part 3: Retrain model
